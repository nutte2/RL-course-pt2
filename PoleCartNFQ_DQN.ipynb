{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeec818f-b6bd-472d-88c5-20b5ced26a30",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1653397180515,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "aeec818f-b6bd-472d-88c5-20b5ced26a30"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc185502-2538-4e7c-9f3b-5c481d5b4d5b",
   "metadata": {
    "executionInfo": {
     "elapsed": 3616,
     "status": "ok",
     "timestamp": 1653397188802,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "dc185502-2538-4e7c-9f3b-5c481d5b4d5b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7670f7a-545d-4852-a699-fa86b6d66bad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1653397188803,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "b7670f7a-545d-4852-a699-fa86b6d66bad",
    "outputId": "c2c22e48-fdc5-46a2-a3be-f26576e4c356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405a78a0-40d7-45ec-b265-0ae2adf8291c",
   "metadata": {
    "id": "405a78a0-40d7-45ec-b265-0ae2adf8291c"
   },
   "source": [
    "# Implementing the NFQ algorithm\n",
    "I've chosen the mountain car environment to try out the NFQ-algorithm\n",
    "Some learning highlights:\n",
    "* Hint-to-goal heuristic seems crucial for the success\n",
    "* Make sure to have cost & min Q / reward max Q in all places.\n",
    "* The number of episodes + increment fed to the training process in each batch seems to hav a large impact\n",
    "* Continuing/stopping the training at the right time point is crucial. I've achieved good results with this implementation, but then ruined a good trained NFQ agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81dffc7c-02ef-4ab3-80c4-51d0fb9a580c",
   "metadata": {
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1653397215101,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "81dffc7c-02ef-4ab3-80c4-51d0fb9a580c"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "# Set up environment and do a test run\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ahHlTYsrxRBp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1653399985845,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "ahHlTYsrxRBp",
    "outputId": "34b363ba-b1c7-4655-fbb0-992d69c1b5d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0654957c-ac37-4628-b72f-437a347e4c52",
   "metadata": {
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1653397221610,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "0654957c-ac37-4628-b72f-437a347e4c52"
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    env.reset()\n",
    "    n_transitions = 200\n",
    "\n",
    "    for i in range(n_transitions):\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "        env.render()\n",
    "        if done:\n",
    "            env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d60f2fbd-2104-4c3a-bb33-bc950215728d",
   "metadata": {
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1653398700018,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "d60f2fbd-2104-4c3a-bb33-bc950215728d"
   },
   "outputs": [],
   "source": [
    "class NFQLearningAgent():\n",
    "    def __init__(self,env,discount_factor, nfq_net):\n",
    "        self.env = env\n",
    "        self.gamma = discount_factor\n",
    "        self.nfq_net = nfq_net\n",
    "        self.x_success_range = 2.4\n",
    "        self.theta_success_range = 8 * 2 * math.pi / 360\n",
    "        \n",
    "        self.x_threshold = 2.4\n",
    "        self.theta_threshold_radians = 12/180*math.pi\n",
    "   \n",
    "    def run_one_episode(self):\n",
    "        episode = []\n",
    "        done = False\n",
    "        total_cost = 0\n",
    "        state = self.env.reset()\n",
    "        \n",
    "        for _ in range(500):\n",
    "            # get best action from the NFQ net\n",
    "            q_s = self.nfq_net.get_qs(state)\n",
    "            action = np.argmin(q_s)\n",
    "            new_state, reward, done, info = self.env.step(action) \n",
    "            # Convert rewards to cost in the interval (0.0, 1,0)\n",
    "            x = new_state[0]\n",
    "            theta = new_state[2]\n",
    "            cost = 0.01\n",
    "            if (x< -self.x_threshold or x > self.x_threshold\n",
    "                or theta < -self.theta_threshold_radians\n",
    "                or theta > self.theta_threshold_radians):\n",
    "                #done = True\n",
    "                cost = 1\n",
    "            # Goal States (S+)\n",
    "            elif (-self.x_success_range < x < self.x_success_range\n",
    "                  and -self.theta_success_range < theta < self.theta_success_range):\n",
    "                #done = False\n",
    "                cost = 0\n",
    "            \n",
    "            \n",
    "            episode.append((state, action, cost, new_state, done, info))\n",
    "            # Update state\n",
    "            state = new_state\n",
    "\n",
    "            total_cost += cost\n",
    "            if done:\n",
    "                break\n",
    "            #if 'TimeLimit.truncated' in info:\n",
    "            #    #print(info)\n",
    "            #    break\n",
    "            \n",
    "        return episode, total_cost\n",
    "    \n",
    "    def generate_experiences(self, n_episodes):\n",
    "        experiences=[]\n",
    "        for _ in range(n_episodes):\n",
    "            episode, _ = self.run_one_episode()\n",
    "            experiences.extend(episode)\n",
    "        return experiences\n",
    "    \n",
    "    def get_goal_experience(self, size):\n",
    "        # Hint-to-goal heuristic with values extracted from env\n",
    "        goal_experiences = []\n",
    "        \n",
    "        for i in range(size):\n",
    "            goal_experiences.append(np.array([np.random.uniform(-0.1, 0.1), \n",
    "                                              np.random.normal(), \n",
    "                                              np.random.uniform(-self.theta_success_range, self.theta_success_range), \n",
    "                                              np.random.normal(), \n",
    "                                              np.random.randint(2)]))\n",
    "        goal_targets = np.zeros(size, dtype = np.float32)\n",
    "        return np.array(goal_experiences), goal_targets\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f53c759-d605-4bf9-9ed6-cd6bcdf71a09",
   "metadata": {
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1653400033552,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "7f53c759-d605-4bf9-9ed6-cd6bcdf71a09"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # Copying the neural network from Riedmiller 2005\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(5, 5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(5, 5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(5, 5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(5, 1),\n",
    "        )\n",
    "          # Initialize weights to [-0.5, 0.5]\n",
    "        def init_weights(m):\n",
    "            if type(m) == nn.Linear:\n",
    "                torch.nn.init.uniform_(m.weight, -0.5, 0.5)\n",
    "              \n",
    "        self.MLP.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        logits = self.MLP(x)\n",
    "        return logits\n",
    "    \n",
    "    def get_qs(self, state):\n",
    "        qs = np.array([self.MLP(torch.cat([torch.FloatTensor(state).to(device), \n",
    "                                           torch.FloatTensor([i]).to(device)], \n",
    "                                          dim=0)).cpu().detach().numpy() for i in range(2)]).flatten()\n",
    "        return qs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bff1cba1-6b3e-41db-ab6f-60ad04f0d4b8",
   "metadata": {
    "id": "bff1cba1-6b3e-41db-ab6f-60ad04f0d4b8"
   },
   "source": [
    "From Riedmiller 2005: This is the pseudo code I'm trying to implement\n",
    "\n",
    "NFQ main() {\n",
    "input: a set of transition samples D; output: Q-value function QN\n",
    "k=0\n",
    "init MLP() → Q0;\n",
    "Do {\n",
    "generate pattern set P = {(inputl, targetl), l = 1, . . . ,#D} where:\n",
    "input_l = sl, ul,\n",
    "target_l = c(sl, ul, s\u0001l) +γ minb Qk(s\u0001l, b)\n",
    "Rprop training(P) → Qk+1\n",
    "k:= k+1\n",
    "} While (k <N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "008a3c5d-b969-4bff-ac95-38441b41d45c",
   "metadata": {
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1653400085924,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "008a3c5d-b969-4bff-ac95-38441b41d45c"
   },
   "outputs": [],
   "source": [
    "def generate_pattern_set(experiences, model, discount_factor, device):\n",
    "    state_b, action_b, cost_b, next_state_b, done_b,_ = zip(*experiences)\n",
    "    state_b = torch.FloatTensor(np.array(state_b)).to(device)\n",
    "    action_b = torch.FloatTensor(np.array(action_b)).to(device)\n",
    "    cost_b = torch.FloatTensor(np.array(cost_b)).to(device)\n",
    "    next_state_b = torch.FloatTensor(np.array(next_state_b)).to(device)\n",
    "    done_b = torch.FloatTensor(np.array(done_b)).to(device)\n",
    "\n",
    "    # Create the input_l = sl, ul\n",
    "    state_action_b = torch.cat([state_b, action_b.unsqueeze(1)], 1)\n",
    "\n",
    "    # Compute minb Qk(s\u0001l, b)\n",
    "    q_next_state_0_b = model(torch.cat([next_state_b, torch.zeros(len(experiences), 1).to(device)], 1)).squeeze()\n",
    "    q_next_state_1_b = model(torch.cat([next_state_b, torch.ones(len(experiences), 1).to(device)], 1)).squeeze()\n",
    "    q_next_state_b,_ = torch.min(torch.stack([q_next_state_0_b, q_next_state_1_b]),dim=0)\n",
    "    \n",
    "    # Create the target_l = c(sl, ul, s\u0001l) +γ minb Qk(s\u0001l, b)\n",
    "    with torch.no_grad():\n",
    "        target_q_values = cost_b + discount_factor * q_next_state_b * (1-done_b)\n",
    "\n",
    "    return state_action_b, target_q_values\n",
    "\n",
    "def train_loop(agent, loss_fn, optimizer, discount_factor, device):\n",
    "    losses=[]\n",
    "    \n",
    "    N_batches = 100000\n",
    "    state_actions = torch.empty(0,5).to(device)\n",
    "    target_q_values = torch.empty(0).to(device)\n",
    "    \n",
    "    #Incrementally add one episode + 100 hint-to-goal heuristics for each batch\n",
    "    for i_batch in range(N_batches):\n",
    "        # Generating experiences\n",
    "        experiences = agent.generate_experiences(1)\n",
    "        # Extract and format state_actions and targets       \n",
    "        state_actions_1, target_q_values_1 = generate_pattern_set(experiences, \n",
    "                                                                  agent.nfq_net, \n",
    "                                                                  discount_factor,\n",
    "                                                                  device)\n",
    "        state_actions = torch.cat([state_actions, state_actions_1], dim=0)\n",
    "        target_q_values = torch.cat([target_q_values, target_q_values_1], dim=0)\n",
    "\n",
    "        # Add hint-to-goal heuristics with a factor of 100\n",
    "        goal_state_action_b, goal_target_q_values = agent.get_goal_experience(100)\n",
    "\n",
    "        goal_state_action_b = torch.FloatTensor(goal_state_action_b).to(device)\n",
    "        goal_target_q_values = torch.FloatTensor(goal_target_q_values).to(device)\n",
    "        \n",
    "        state_actions = torch.cat([state_actions, goal_state_action_b], dim=0)\n",
    "        target_q_values = torch.cat([target_q_values, goal_target_q_values], dim=0)\n",
    "            \n",
    "        # Compute prediction and loss\n",
    "        pred = model(state_actions).squeeze()\n",
    "        \n",
    "        loss = loss_fn(pred, target_q_values)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i_batch%1000 == 0:\n",
    "            success_rate = test_loop(NFQagent, 100)\n",
    "            if (success_rate >= 99.0):\n",
    "                break\n",
    "\n",
    "    return losses\n",
    "\n",
    "\n",
    "def test_loop(agent, n_trials):\n",
    "    success = 0.\n",
    "    episode_lengths=[]\n",
    "    for i in range (n_trials):\n",
    "        episode, total_cost = agent.run_one_episode()\n",
    "        done = episode[-1][-2]\n",
    "        info = episode[-1][-1]\n",
    "        episode_lengths.append(len(episode))\n",
    "        if done and ('TimeLimit.truncated' in info and info['TimeLimit.truncated']):\n",
    "            success+=1.\n",
    "        \n",
    "    success /= n_trials\n",
    "    print(f\"Test run, average length: {(np.mean(episode_lengths)):>0.1f}, max: {(np.max(episode_lengths)):>0.1f}\")\n",
    "    print(f\"Success rate: {(100*success):>0.1f}%\")\n",
    "    return success*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2362a132-567f-4d10-962d-4feb7b5305a7",
   "metadata": {
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1653400088280,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "2362a132-567f-4d10-962d-4feb7b5305a7"
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "gamma = 0.95\n",
    "loss_fn=nn.MSELoss()\n",
    "optimizer = torch.optim.Rprop(model.parameters())\n",
    "\n",
    "NFQagent = NFQLearningAgent(env,gamma, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc0591a9-56eb-43f6-a763-53f998bd61a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6138,
     "status": "ok",
     "timestamp": 1653400096563,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "fc0591a9-56eb-43f6-a763-53f998bd61a7",
    "outputId": "00734a6a-90dc-4d04-a4d9-d6bb097e912f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Test run, average length: 9.4, max: 11.0\n",
      "Success rate: 0.0%\n",
      "Test run, average length: 67.2, max: 98.0\n",
      "Success rate: 0.0%\n",
      "Test run, average length: 101.2, max: 105.0\n",
      "Success rate: 0.0%\n",
      "Test run, average length: 119.8, max: 127.0\n",
      "Success rate: 0.0%\n",
      "Test run, average length: 182.3, max: 200.0\n",
      "Success rate: 10.0%\n",
      "Test run, average length: 172.4, max: 200.0\n",
      "Success rate: 0.0%\n",
      "Test run, average length: 199.8, max: 200.0\n",
      "Success rate: 98.0%\n",
      "Test run, average length: 176.9, max: 200.0\n",
      "Success rate: 1.0%\n",
      "Test run, average length: 159.0, max: 200.0\n",
      "Success rate: 1.0%\n",
      "Test run, average length: 148.0, max: 171.0\n",
      "Success rate: 0.0%\n",
      "Test run, average length: 156.2, max: 200.0\n",
      "Success rate: 9.0%\n",
      "Test run, average length: 90.0, max: 137.0\n",
      "Success rate: 0.0%\n",
      "Test run, average length: 62.3, max: 122.0\n",
      "Success rate: 0.0%\n",
      "Test run, average length: 46.6, max: 118.0\n",
      "Success rate: 0.0%\n",
      "Test run, average length: 79.9, max: 129.0\n",
      "Success rate: 0.0%\n",
      "Test run, average length: 105.2, max: 142.0\n",
      "Success rate: 0.0%\n",
      "Test run, average length: 121.0, max: 140.0\n",
      "Success rate: 0.0%\n",
      "Test run, average length: 125.2, max: 158.0\n",
      "Success rate: 0.0%\n",
      "Test run, average length: 138.8, max: 167.0\n",
      "Success rate: 0.0%\n",
      "Test run, average length: 153.2, max: 200.0\n",
      "Success rate: 1.0%\n",
      "Test run, average length: 177.3, max: 200.0\n",
      "Success rate: 13.0%\n",
      "Test run, average length: 198.3, max: 200.0\n",
      "Success rate: 85.0%\n",
      "Test run, average length: 200.0, max: 200.0\n",
      "Success rate: 100.0%\n",
      "Test run, average length: 200.0, max: 200.0\n",
      "Success rate: 100.0%\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "losses=[]\n",
    "epochs = 1\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    losses.extend(train_loop(NFQagent, loss_fn, optimizer, gamma, device))\n",
    "    success_rate = test_loop(NFQagent, 100)\n",
    "    if (success_rate >= 99.0):\n",
    "        break\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b12ed6fb-012e-4fd5-a8be-caa38dbee975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0e404e7e80>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "573bdb6f-2785-4bb8-9f5a-5360fb3011c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1590,
     "status": "ok",
     "timestamp": 1653400137049,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "573bdb6f-2785-4bb8-9f5a-5360fb3011c1",
    "outputId": "69d6eddd-31fc-48f5-b6a3-c4f070caac1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test run, average length: 200.0, max: 200.0\n",
      "Success rate: 99.6%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do a test run using the trained NFQ agent\n",
    "test_loop(NFQagent, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6ae22e9-5a37-4d0b-bba5-7adcf051b665",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "executionInfo": {
     "elapsed": 630,
     "status": "error",
     "timestamp": 1653400142410,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "f6ae22e9-5a37-4d0b-bba5-7adcf051b665",
    "outputId": "02188ba7-435b-48e0-d46b-7f4e91d15f76"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_mm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6936/3136760860.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_transitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mq_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNFQagent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfq_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print(action, q_s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6936/3136760860.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_transitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mq_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNFQagent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfq_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print(action, q_s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6936/1257077508.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_mm)"
     ]
    }
   ],
   "source": [
    "# For visualization\n",
    "state = env.reset()\n",
    "n_transitions = 1000\n",
    "\n",
    "for i in range(n_transitions):\n",
    "    q_s = np.array([NFQagent.nfq_net(torch.cat([torch.FloatTensor(state), torch.FloatTensor([i])], dim=0)).detach().numpy() for i in range(2)]).flatten()\n",
    "    action = np.argmin(q_s)\n",
    "    #print(action, q_s)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    \n",
    "    env.render()\n",
    "    if done:\n",
    "        if 'TimeLimit.truncated' in info:\n",
    "            print(info)\n",
    "        else:\n",
    "            print('Terminated: Failed')\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928b545c-4901-4b6a-8ba3-9d187fe011af",
   "metadata": {
    "id": "928b545c-4901-4b6a-8ba3-9d187fe011af"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "PoleCartNFQ_DQN.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/pkimstrand/RL-course-pt2/blob/main/PoleCartNFQ_DQN.ipynb",
     "timestamp": 1653397147341
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
