{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeec818f-b6bd-472d-88c5-20b5ced26a30",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1653397180515,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "aeec818f-b6bd-472d-88c5-20b5ced26a30"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc185502-2538-4e7c-9f3b-5c481d5b4d5b",
   "metadata": {
    "executionInfo": {
     "elapsed": 3616,
     "status": "ok",
     "timestamp": 1653397188802,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "dc185502-2538-4e7c-9f3b-5c481d5b4d5b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7670f7a-545d-4852-a699-fa86b6d66bad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1653397188803,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "b7670f7a-545d-4852-a699-fa86b6d66bad",
    "outputId": "c2c22e48-fdc5-46a2-a3be-f26576e4c356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405a78a0-40d7-45ec-b265-0ae2adf8291c",
   "metadata": {
    "id": "405a78a0-40d7-45ec-b265-0ae2adf8291c"
   },
   "source": [
    "# Implementing the NFQ algorithm\n",
    "I've chosen the mountain car environment to try out the NFQ-algorithm\n",
    "Some learning highlights:\n",
    "* Hint-to-goal heuristic seems crucial for the success\n",
    "* Make sure to have cost & min Q / reward max Q in all places.\n",
    "* The number of episodes + increment fed to the training process in each batch seems to hav a large impact\n",
    "* Continuing/stopping the training at the right time point is crucial. I've achieved good results with this implementation, but then ruined a good trained NFQ agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "81dffc7c-02ef-4ab3-80c4-51d0fb9a580c",
   "metadata": {
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1653397215101,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "81dffc7c-02ef-4ab3-80c4-51d0fb9a580c"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "# Set up environment and do a test run\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ahHlTYsrxRBp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1653399985845,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "ahHlTYsrxRBp",
    "outputId": "34b363ba-b1c7-4655-fbb0-992d69c1b5d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0654957c-ac37-4628-b72f-437a347e4c52",
   "metadata": {
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1653397221610,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "0654957c-ac37-4628-b72f-437a347e4c52"
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    env.reset()\n",
    "    n_transitions = 200\n",
    "\n",
    "    for i in range(n_transitions):\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "        env.render()\n",
    "        if done:\n",
    "            env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d60f2fbd-2104-4c3a-bb33-bc950215728d",
   "metadata": {
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1653398700018,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "d60f2fbd-2104-4c3a-bb33-bc950215728d"
   },
   "outputs": [],
   "source": [
    "class NFQLearningAgent():\n",
    "    def __init__(self,env,discount_factor, nfq_net):\n",
    "        self.env = env\n",
    "        self.gamma = discount_factor\n",
    "        self.nfq_net = nfq_net\n",
    "        self.x_success_range = 2.4\n",
    "        self.theta_success_range = 12 * 2 * math.pi / 360\n",
    "        \n",
    "        self.x_threshold = 2.4\n",
    "        self.theta_threshold_radians = math.pi / 2\n",
    "   \n",
    "    def run_one_episode(self):\n",
    "        episode = []\n",
    "        done = False\n",
    "        total_cost = 0\n",
    "        state = self.env.reset()\n",
    "        \n",
    "        for _ in range(500):\n",
    "            # get best action from the NFQ net\n",
    "            q_s = self.nfq_net.get_qs(state)\n",
    "            action = np.argmin(q_s)\n",
    "            new_state, reward, done, info = self.env.step(action) \n",
    "            # Convert rewards to cost in the interval (0.0, 1,0)\n",
    "            x = new_state[0]\n",
    "            theta = new_state[2]\n",
    "            cost = 0.01\n",
    "            if (x< -self.x_threshold or x > self.x_threshold\n",
    "                or theta < -self.theta_threshold_radians\n",
    "                or theta > self.theta_threshold_radians):\n",
    "                done = True\n",
    "                cost = 1\n",
    "            # Goal States (S+)\n",
    "            elif (-self.x_success_range < x < self.x_success_range\n",
    "                  and -self.theta_success_range < theta < self.theta_success_range):\n",
    "                done = False\n",
    "                cost = 0\n",
    "            \n",
    "            \n",
    "            episode.append((state, action, cost, new_state, done, info))\n",
    "            # Update state\n",
    "            state = new_state\n",
    "\n",
    "            total_cost += cost\n",
    "            if done:\n",
    "                break\n",
    "            #if 'TimeLimit.truncated' in info:\n",
    "            #    #print(info)\n",
    "            #    break\n",
    "            \n",
    "        return episode, total_cost\n",
    "    \n",
    "    def generate_experiences(self, n_episodes):\n",
    "        experiences=[]\n",
    "        for _ in range(n_episodes):\n",
    "            episode, _ = self.run_one_episode()\n",
    "            experiences.extend(episode)\n",
    "        return experiences\n",
    "    \n",
    "    def get_goal_experience(self, size):\n",
    "        # Hint-to-goal heuristic with values extracted from env\n",
    "        goal_experiences = []\n",
    "        \n",
    "        for i in range(size):\n",
    "            goal_experiences.append(np.array([np.random.uniform(-0.05, 0.05), \n",
    "                                              np.random.normal(), \n",
    "                                              np.random.uniform(-self.theta_success_range, self.theta_success_range), \n",
    "                                              np.random.normal(), \n",
    "                                              np.random.randint(2)]))\n",
    "        goal_targets = np.zeros(size, dtype = np.float32)\n",
    "        return np.array(goal_experiences), goal_targets\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7f53c759-d605-4bf9-9ed6-cd6bcdf71a09",
   "metadata": {
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1653400033552,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "7f53c759-d605-4bf9-9ed6-cd6bcdf71a09"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # Copying the neural network from Riedmiller 2005\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(5, 5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(5, 5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(5, 5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(5, 1),\n",
    "        )\n",
    "          # Initialize weights to [-0.5, 0.5]\n",
    "        def init_weights(m):\n",
    "            if type(m) == nn.Linear:\n",
    "                torch.nn.init.uniform_(m.weight, -0.5, 0.5)\n",
    "              \n",
    "        self.MLP.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        logits = self.MLP(x)\n",
    "        return logits\n",
    "    \n",
    "    def get_qs(self, state):\n",
    "        qs = np.array([self.MLP(torch.cat([torch.FloatTensor(state), \n",
    "                                           torch.FloatTensor([i])], \n",
    "                                          dim=0)).detach().numpy() for i in range(2)]).flatten()\n",
    "        return qs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bff1cba1-6b3e-41db-ab6f-60ad04f0d4b8",
   "metadata": {
    "id": "bff1cba1-6b3e-41db-ab6f-60ad04f0d4b8"
   },
   "source": [
    "From Riedmiller 2005: This is the pseudo code I'm trying to implement\n",
    "\n",
    "NFQ main() {\n",
    "input: a set of transition samples D; output: Q-value function QN\n",
    "k=0\n",
    "init MLP() → Q0;\n",
    "Do {\n",
    "generate pattern set P = {(inputl, targetl), l = 1, . . . ,#D} where:\n",
    "input_l = sl, ul,\n",
    "target_l = c(sl, ul, s\u0001l) +γ minb Qk(s\u0001l, b)\n",
    "Rprop training(P) → Qk+1\n",
    "k:= k+1\n",
    "} While (k <N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "008a3c5d-b969-4bff-ac95-38441b41d45c",
   "metadata": {
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1653400085924,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "008a3c5d-b969-4bff-ac95-38441b41d45c"
   },
   "outputs": [],
   "source": [
    "def generate_pattern_set(experiences, model, discount_factor):\n",
    "    state_b, action_b, cost_b, next_state_b, done_b,_ = zip(*experiences)\n",
    "    state_b = torch.FloatTensor(np.array(state_b))\n",
    "    action_b = torch.FloatTensor(np.array(action_b))\n",
    "    cost_b = torch.FloatTensor(np.array(cost_b))\n",
    "    next_state_b = torch.FloatTensor(np.array(next_state_b))\n",
    "    done_b = torch.FloatTensor(np.array(done_b))\n",
    "\n",
    "    # Create the input_l = sl, ul\n",
    "    state_action_b = torch.cat([state_b, action_b.unsqueeze(1)], 1)\n",
    "\n",
    "    # Compute minb Qk(s\u0001l, b)\n",
    "    q_next_state_0_b = model(torch.cat([next_state_b, torch.zeros(len(experiences), 1)], 1)).squeeze()\n",
    "    q_next_state_1_b = model(torch.cat([next_state_b, torch.ones(len(experiences), 1)], 1)).squeeze()\n",
    "    q_next_state_2_b = model(torch.cat([next_state_b, torch.full((len(experiences), 1), fill_value=2)], 1)).squeeze()\n",
    "    q_next_state_b,_ = torch.min(torch.stack([q_next_state_0_b, q_next_state_1_b, q_next_state_2_b]),dim=0)\n",
    "    \n",
    "    # Create the target_l = c(sl, ul, s\u0001l) +γ minb Qk(s\u0001l, b)\n",
    "    with torch.no_grad():\n",
    "        target_q_values = cost_b + discount_factor * q_next_state_b * (done_b)\n",
    "\n",
    "    return state_action_b, target_q_values\n",
    "\n",
    "def train_loop(agent, loss_fn, optimizer, discount_factor, device):\n",
    "    losses=[]\n",
    "    \n",
    "    N_batches = 1000\n",
    "    state_actions = torch.empty(0,5)\n",
    "    target_q_values = torch.empty(0)\n",
    "    \n",
    "    #Incrementally add one episode + 100 hint-to-goal heuristics for each batch\n",
    "    for i_batch in range(N_batches):\n",
    "        # Generating experiences\n",
    "        experiences = agent.generate_experiences(1)\n",
    "        # Extract and format state_actions and targets       \n",
    "        state_actions_1, target_q_values_1 = generate_pattern_set(experiences, agent.nfq_net, discount_factor)\n",
    "        state_actions = torch.cat([state_actions, state_actions_1], dim=0)\n",
    "        target_q_values = torch.cat([target_q_values, target_q_values_1], dim=0)\n",
    "\n",
    "        # Add hint-to-goal heuristics with a factor of 100\n",
    "        goal_state_action_b, goal_target_q_values = agent.get_goal_experience(100)\n",
    "\n",
    "        goal_state_action_b = torch.FloatTensor(goal_state_action_b)\n",
    "        goal_target_q_values = torch.FloatTensor(goal_target_q_values)\n",
    "        \n",
    "        state_actions = torch.cat([state_actions, goal_state_action_b], dim=0)\n",
    "        target_q_values = torch.cat([target_q_values, goal_target_q_values], dim=0)\n",
    "            \n",
    "        # Compute prediction and loss\n",
    "        pred = model(state_actions).squeeze()\n",
    "        \n",
    "        loss = loss_fn(pred, target_q_values)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return losses\n",
    "\n",
    "\n",
    "def test_loop(agent, n_trials):\n",
    "    success = 0.\n",
    "    average_len = 0\n",
    "    for i in range (n_trials):\n",
    "        episode, total_cost = agent.run_one_episode()\n",
    "        done = episode[-1][-2]\n",
    "        info = episode[-1][-1]\n",
    "        average_len += len(episode)\n",
    "        if done and ('TimeLimit.truncated' in info and info['TimeLimit.truncated']):\n",
    "            success+=1.\n",
    "        \n",
    "    success /= n_trials\n",
    "    print(f\"Test run, average length: {(average_len/n_trials):>0.1f}\")\n",
    "    print(f\"Success rate: {(100*success):>0.1f}%\")\n",
    "    return success*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2362a132-567f-4d10-962d-4feb7b5305a7",
   "metadata": {
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1653400088280,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "2362a132-567f-4d10-962d-4feb7b5305a7"
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork()#.to(device)\n",
    "gamma = 0.95\n",
    "loss_fn=nn.MSELoss()\n",
    "optimizer = torch.optim.Rprop(model.parameters())\n",
    "\n",
    "NFQagent = NFQLearningAgent(env,gamma, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fc0591a9-56eb-43f6-a763-53f998bd61a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6138,
     "status": "ok",
     "timestamp": 1653400096563,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "fc0591a9-56eb-43f6-a763-53f998bd61a7",
    "outputId": "00734a6a-90dc-4d04-a4d9-d6bb097e912f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_318286/2774625657.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNFQagent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msuccess_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNFQagent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msuccess_rate\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m99.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_318286/2947657258.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(agent, loss_fn, optimizer, discount_factor, reset)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mN_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "losses=[]\n",
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    losses.extend(train_loop(NFQagent, loss_fn, optimizer, gamma, device))\n",
    "    success_rate = test_loop(NFQagent, 100)\n",
    "    if (success_rate >= 99.0):\n",
    "        break\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ed6fb-012e-4fd5-a8be-caa38dbee975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdd6f0fef10>]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573bdb6f-2785-4bb8-9f5a-5360fb3011c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1590,
     "status": "ok",
     "timestamp": 1653400137049,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "573bdb6f-2785-4bb8-9f5a-5360fb3011c1",
    "outputId": "69d6eddd-31fc-48f5-b6a3-c4f070caac1d"
   },
   "outputs": [],
   "source": [
    "# Do a test run using the trained NFQ agent\n",
    "test_loop(NFQagent, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f6ae22e9-5a37-4d0b-bba5-7adcf051b665",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "executionInfo": {
     "elapsed": 630,
     "status": "error",
     "timestamp": 1653400142410,
     "user": {
      "displayName": "Peter Kimstrand",
      "userId": "08323163514993465067"
     },
     "user_tz": -120
    },
    "id": "f6ae22e9-5a37-4d0b-bba5-7adcf051b665",
    "outputId": "02188ba7-435b-48e0-d46b-7f4e91d15f76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TimeLimit.truncated': True}\n",
      "{'TimeLimit.truncated': True}\n",
      "{'TimeLimit.truncated': True}\n",
      "{'TimeLimit.truncated': True}\n",
      "{'TimeLimit.truncated': True}\n"
     ]
    }
   ],
   "source": [
    "# For visualization\n",
    "state = env.reset()\n",
    "n_transitions = 1000\n",
    "\n",
    "for i in range(n_transitions):\n",
    "    q_s = np.array([NFQagent.nfq_net(torch.cat([torch.FloatTensor(state), torch.FloatTensor([i])], dim=0)).detach().numpy() for i in range(2)]).flatten()\n",
    "    action = np.argmin(q_s)\n",
    "    #print(action, q_s)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    \n",
    "    env.render()\n",
    "    if done:\n",
    "        if 'TimeLimit.truncated' in info:\n",
    "            print(info)\n",
    "        else:\n",
    "            print('Terminated: Failed')\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928b545c-4901-4b6a-8ba3-9d187fe011af",
   "metadata": {
    "id": "928b545c-4901-4b6a-8ba3-9d187fe011af"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "PoleCartNFQ_DQN.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/pkimstrand/RL-course-pt2/blob/main/PoleCartNFQ_DQN.ipynb",
     "timestamp": 1653397147341
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
